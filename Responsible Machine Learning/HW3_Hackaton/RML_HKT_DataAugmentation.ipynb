{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNpxrINK62qAZBEyWb2fOXh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Data Augmentation for the JUSTICE dataset with GPT-3.5\n","\n","## Hackathon : Responsible Machine Learning (2022-2023)\n","\n","### Théo Di Piazza"],"metadata":{"id":"W601uUkDurO4"}},{"cell_type":"markdown","source":["# 1 - Setup the notebook"],"metadata":{"id":"dikf24UmwLO7"}},{"cell_type":"code","source":["#@title Install Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VcZD1m6qwGv-","executionInfo":{"status":"ok","timestamp":1674221650993,"user_tz":-60,"elapsed":19362,"user":{"displayName":"Théo Di Piazza","userId":"01981372158233418695"}},"outputId":"66a4c270-1115-498c-ac27-9b1d95ac67eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#@title Install libraries (Require OpenAI)\n","!pip install openai"],"metadata":{"id":"3qPMrJpqtf7H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Import libraries\n","import os\n","import openai\n","import pandas as pd"],"metadata":{"id":"GNB7mmfzvqKz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2 - Perform Data Augmentation for label 1 (acceptable)"],"metadata":{"id":"4SrCZcKqweBq"}},{"cell_type":"code","source":["#@title Read dataset to extract beginning of sentences\n","path_csv = '/path/to/data/justice_train.csv' # csv path\n","df = pd.read_csv(path_csv) # read df\n","df = df.sample(frac=1) # shuffle"],"metadata":{"id":"hgHOYjZav-hs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Iterate over dataset and generate the new reason\n","\n","# Please, find your own API key on OpenAI website\n","openai.api_key = 'YOUR_API' \n","\n","generated_sentences = [] # all full generated sentences\n","\n","# For each sentence of the dataset\n","for sent in df['generations']:\n","\n","  # Check if 'because' is present\n","  if('because' in sent):\n","\n","    # Extract action to start the sentence\n","    action_start = sent.split('because')[0] + 'because ' # beginning of the sentence\n","    input = \"Please generate the end of the sentence : \\'\" + action_start + \"\\'\" # input to give to OpenAI model\n","\n","    # Generate end of the sentence with the API\n","    response = openai.Completion.create(\n","                model=\"text-davinci-003\",\n","                prompt=input,\n","                temperature=0.9,\n","                max_tokens=150,\n","                top_p=1,\n","                frequency_penalty=0,\n","                presence_penalty=0.6)\n","    \n","    # Extraction of the generation\n","    generated_reason = response['choices'][0]['text'].replace('\\n', '')\n","\n","    # Full sentence as string\n","    new_sent = action_start + generated_reason\n","\n","    # Add it to the list\n","    generated_sentences.append(new_sent)"],"metadata":{"id":"8aTQcoDgwv2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Save it as csv\n","justice = [1 for i in range(len(all_sentences))] # labels 1\n","df = pd.DataFrame({'scenario': all_sentences, 'label': justice}) # scenario\n","path_csv = '/path/to/csv/generations_labels1.csv' # path to save\n","df.to_csv(path_csv) # save csv"],"metadata":{"id":"4x5EksoNxebi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3 - Perform Data Augmentation for label 0 (not acceptable)"],"metadata":{"id":"7et63Kn9Y5Ty"}},{"cell_type":"code","source":["#@title Read dataset to extract beginning of sentences\n","path_csv = '/path/to/data/justice_train.csv' # csv path\n","df = pd.read_csv(path_csv) # read df\n","df = df.sample(frac=1) # shuffle"],"metadata":{"id":"6P1BzNKIY-bT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Iterate over dataset and generate the new reason\n","\n","# Please, find your own API key on OpenAI website\n","openai.api_key = 'YOUR_API'\n","\n","generated_sentences = [] # all full generated sentences\n","\n","# For each sentence of the dataset\n","for sent in df['generations']:\n","\n","  # Check if 'because' is present\n","  if('because' in sent):\n","\n","    # Extract action to start the sentence\n","    action_start = sent.split('because')[0] + 'because ' # beginning of the sentence\n","    input = \"Please generate the end of the sentence with an incoherent explanation : \\'\" + action_start + \"\\'\" # input to give to OpenAI model\n","\n","    # Generate end of the sentence with the API\n","    response = openai.Completion.create(\n","                model=\"text-davinci-003\",\n","                prompt=input,\n","                temperature=0.9,\n","                max_tokens=150,\n","                top_p=1,\n","                frequency_penalty=0,\n","                presence_penalty=0.6)\n","    \n","    # Extraction of the generation\n","    generated_reason = response['choices'][0]['text'].replace('\\n', '')\n","\n","    # Full sentence as string\n","    new_sent = action_start + generated_reason\n","\n","    # Add it to the list\n","    generated_sentences.append(new_sent)"],"metadata":{"id":"woGfwcJxcdLs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Save it as csv\n","justice = [0 for i in range(len(all_sentences))] # labels 0\n","df = pd.DataFrame({'scenario': all_sentences, 'label': justice}) # scenario\n","path_csv = '/path/to/csv/generations_labels0.csv' # path to save\n","df.to_csv(path_csv) # save csv"],"metadata":{"id":"1S-W5IU0q0dw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# END of Data Augmentation notebook."],"metadata":{"id":"xJj8tqPjyCRZ"}}]}