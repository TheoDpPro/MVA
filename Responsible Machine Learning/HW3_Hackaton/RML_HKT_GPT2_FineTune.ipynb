{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ783Sf4fEQr"
      },
      "source": [
        "# Data Augmentation for the JUSTICE dataset with GPT-3.5\n",
        "\n",
        "## Hackathon : Responsible Machine Learning (2022-2023)\n",
        "\n",
        "### Th√©o Di Piazza"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Setup the notebook"
      ],
      "metadata": {
        "id": "4Rb1IUUjziu2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixip9QUjbDS9"
      },
      "outputs": [],
      "source": [
        "#@title Download libraries (Require transformers)\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iW99dgDLa9J3"
      },
      "outputs": [],
      "source": [
        "#@title Import libraries\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch.optim import Adam, AdamW, SGD\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2TokenizerFast, GPT2ForSequenceClassification, GPT2Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5TWQYzKf_4_"
      },
      "outputs": [],
      "source": [
        "#@title Paths\n",
        "path_project = '/content'\n",
        "\n",
        "path_dataug = os.path.join(path_project, 'justice_augmented.csv') # dataset for data aug\n",
        "path_train = os.path.join(path_project, 'justice_train.csv') # train justice \n",
        "path_test = os.path.join(path_project, 'justice_test.csv') # test justice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tk4Iql_FascO"
      },
      "source": [
        "# 1 - Load model for sentence classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model and Tokenizer\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # device\n",
        "configuration = GPT2Config() # config\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(\"distilgpt2\") # token\n",
        "tokenizer.pad_token = tokenizer.eos_token # padding token to handle batch sizes\n",
        "\n",
        "# Model\n",
        "model = GPT2ForSequenceClassification(configuration).from_pretrained(\"distilgpt2\", num_labels=2).to(device) # GPT2 Model\n",
        "model.config.pad_token_id = model.config.eos_token_id"
      ],
      "metadata": {
        "id": "DPk4SMA-K2ZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8606bf8a-0913-4238-d4de-ece5c29a97cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilgpt2 were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
            "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at distilgpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Load JUSTICE data from ETHICS"
      ],
      "metadata": {
        "id": "78-MdXmv0mXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 - Recreate train/test"
      ],
      "metadata": {
        "id": "CoOKO_1C072P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load initialize data to recreate dataset from scratch\n",
        "\n",
        "# Load and concatenate train, test from JUSTICE then split\n",
        "train = pd.read_csv(path_train)\n",
        "test = pd.read_csv(path_test)\n",
        "df = pd.concat([train, test])\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, shuffle=True, random_state=42) # split\n",
        "\n",
        "# Add data augmentation to the train set if needed\n",
        "'''data_aug = pd.read_csv(path_dataug)\n",
        "train_df = pd.concat([train_df, data_aug])'''"
      ],
      "metadata": {
        "id": "6S3pIz_N7_e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8c7ca960-fb49-4be7-af6f-926e6938b3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data_aug = pd.read_csv(path_dataug)\\ntrain_df = pd.concat([train_df, data_aug])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 - Class CustomDataset"
      ],
      "metadata": {
        "id": "AQNNOExg0-tc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpu5Hy5kg-OF"
      },
      "outputs": [],
      "source": [
        "#@title Class CustomDataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  '''\n",
        "    CustomDataset to fine-tune or evaluate GPT-2 on JUSTICE\n",
        "    path_project (str): path of the project\n",
        "    train (True or False): True to load train set, False otherwise\n",
        "  '''\n",
        "  def __init__(self, path_project, train=True):\n",
        "    super(Dataset, self).__init__()\n",
        "\n",
        "    # Load train \n",
        "    if(train):\n",
        "      self.df = train_df\n",
        "    # Or load test\n",
        "    else:\n",
        "      self.df = test_df\n",
        "\n",
        "    # Initialize labels and texts\n",
        "    self.labels = np.array(list(self.df['label'])) # 1 if fair, 0 otherwise\n",
        "    self.texts = list(self.df[\"scenario\"].astype(str))\n",
        "\n",
        "  def __len__(self):\n",
        "    '''\n",
        "      Return length\n",
        "    '''\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    '''\n",
        "      Return texts, labels \n",
        "    '''\n",
        "    # Get texts\n",
        "    texts = self.texts[index]\n",
        "    # Get labels\n",
        "    labels = self.labels[index]\n",
        "\n",
        "    return texts, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 - Load Data with CustomLoader"
      ],
      "metadata": {
        "id": "vdNaGvgQ1gT2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9KoIylNhwzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3511a0b-09bf-4140-9bb9-44bed7988cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train and Test datas loaded! Train: 19596 samples - Test: 4899 samples!\n"
          ]
        }
      ],
      "source": [
        "#@title Load data with DataLoader\n",
        "\n",
        "# Dataset\n",
        "dataset_train = CustomDataset(path_project, train=True)\n",
        "dataset_test = CustomDataset(path_project, train=False)\n",
        "\n",
        "# DataLoader\n",
        "batch_size = 32\n",
        "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
        "loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "print(f'Train and Test datas loaded! Train: {len(dataset_train)} samples - Test: {len(dataset_test)} samples!')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Training"
      ],
      "metadata": {
        "id": "Qao2P4EO1l5T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 - Optimizer"
      ],
      "metadata": {
        "id": "WZkJJ9hh1rQ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWwBtZFMlsyY"
      },
      "outputs": [],
      "source": [
        "#@title Optimizer - Frozen transformer\n",
        "decomposed_params = [{'params': model.score.parameters()}]\n",
        "optimizer = AdamW(decomposed_params, lr = 1e-4, eps = 1e-8)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Optimizer - Not frozen transformer\n",
        "decomposed_params = [{'params': model.score.parameters(), 'lr':1e-4}, {'params': model.transformer.parameters(), 'lr':1e-5}]\n",
        "optimizer = AdamW(decomposed_params, eps=1e-8)"
      ],
      "metadata": {
        "id": "sNKOM3VeJJKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 - Training step"
      ],
      "metadata": {
        "id": "Khx5nf_j1ujP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pziWcYgxl9-7"
      },
      "outputs": [],
      "source": [
        "#@title evaluate function\n",
        "def evaluate(model, test_loader):\n",
        "  '''\n",
        "  Evaluate a model for a given test_loader.\n",
        "  Returns accuracy, loss\n",
        "  '''\n",
        "  loss_test = 0\n",
        "  labels_test, predictions_test = [], []\n",
        "  model.eval()\n",
        "\n",
        "  for batch_id, (texts, label) in enumerate(test_loader):\n",
        "    \n",
        "    # Get inputs_id and attention_mask from encoding\n",
        "    encoding = tokenizer(list(texts), return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # Make prediction\n",
        "    outputs = model(input_ids, attention_mask=attention_mask, labels=label)\n",
        "    loss, logits = outputs[0].item(), outputs[1] # logits\n",
        "    p = torch.nn.functional.softmax(logits, dim=1) # probabilities\n",
        "    predictions = p.argmax(axis=1).tolist() # class predicted\n",
        "\n",
        "    # Save loss, labels and predictions\n",
        "    loss_test += loss\n",
        "    labels_test += label.tolist()\n",
        "    predictions_test += predictions\n",
        "\n",
        "  # Compute accuracy\n",
        "  correct = (np.array(predictions_test) == np.array(labels_test))\n",
        "  accuracy = correct.sum() / correct.size\n",
        "\n",
        "  return accuracy, loss_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OhydWNAiHyS"
      },
      "outputs": [],
      "source": [
        "#@title Train steps\n",
        "\n",
        "epochs = 40\n",
        "loss_train, loss_test = [], []\n",
        "accuracy_train, accuracy_test = [], []\n",
        "\n",
        "print(f'- START! epochs: {epochs} - device: {device} - train: {len(dataset_train)} samples! -\\n')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  labels_epoch, predictions_epoch = [], []\n",
        "  loss_train_epoch = 0\n",
        "\n",
        "  for batch_id, (texts, label) in enumerate(loader_train):\n",
        "    \n",
        "    model.train()\n",
        "\n",
        "    # Get inputs_id and attention_mask from encoding\n",
        "    encoding = tokenizer(list(texts), return_tensors='pt', padding=True, truncation=True)\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "    label = label.to(device)\n",
        "\n",
        "    # Make prediction\n",
        "    outputs = model(input_ids, attention_mask=attention_mask, labels=label)\n",
        "    loss, logits = outputs.loss, outputs[1] # loss, logits\n",
        "    p = torch.nn.functional.softmax(logits, dim=1) # probabilities\n",
        "    predictions = p.argmax(axis=1).tolist() # class predicted\n",
        "\n",
        "    # Save loss, labels and predictions\n",
        "    loss_train_epoch += loss.item()\n",
        "    labels_epoch += label.tolist()\n",
        "    predictions_epoch += predictions\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (batch_id%100==0) and (not batch_id==0):\n",
        "      print(f'--- Step {batch_id}/{len(loader_train)}. Avg.loss = {loss_train_epoch/batch_id:.2f}')\n",
        "\n",
        "  # Compute accuracy train for the epoch\n",
        "  correct = (np.array(predictions_epoch) == np.array(labels_epoch))\n",
        "  accuracy_train_epoch = correct.sum() / correct.size\n",
        "\n",
        "  # Compute accuracy train for the epoch\n",
        "  accuracy_test_epoch, loss_test_epoch = evaluate(model, loader_test)\n",
        "  \n",
        "  print(f'-- Train - Epoch {epoch} : Accuracy: {accuracy_train_epoch:.2f} - Avg.Loss: {loss_train_epoch/len(loader_train):.2f} --')\n",
        "  print(f'-- Validation - Epoch {epoch} : Accuracy: {accuracy_test_epoch:.2f} - Avg.Loss: {loss_test_epoch/len(loader_test):.2f} --\\n')\n",
        "\n",
        "  # Save metrics\n",
        "  loss_train.append(loss_train_epoch); loss_test.append(loss_test_epoch);\n",
        "  accuracy_train.append(accuracy_train_epoch); accuracy_test.append(accuracy_test_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 - Save metrics"
      ],
      "metadata": {
        "id": "w8CD6orD2BTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save metrics\n",
        "metrics = {'loss_train': loss_train,\n",
        "           'loss_test': loss_test,\n",
        "           'accuracy_train': accuracy_train,\n",
        "           'accuracy_test': accuracy_test}\n",
        "with open('metrics_without_FT_v2.txt', \"w\") as output:\n",
        "    output.write(str(metrics))\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'model_with_finetuning.pth')"
      ],
      "metadata": {
        "id": "x6tKBuxodCyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Qualitative results"
      ],
      "metadata": {
        "id": "MLgNNsl89dn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extract some examples\n",
        "\n",
        "model.eval()\n",
        "# Iterate over test loader to extract some examples\n",
        "for batch_id, (texts, label) in enumerate(loader_test):\n",
        "  \n",
        "  # Get inputs_id and attention_mask from encoding\n",
        "  encoding = tokenizer(list(texts), return_tensors='pt', padding=True, truncation=True)\n",
        "  input_ids = encoding['input_ids'].to(device)\n",
        "  attention_mask = encoding['attention_mask'].to(device)\n",
        "  label = label.to(device)\n",
        "\n",
        "  # Make prediction\n",
        "  outputs = model(input_ids, attention_mask=attention_mask, labels=label)\n",
        "  loss, logits = outputs[0].item(), outputs[1] # logits\n",
        "  p = torch.nn.functional.softmax(logits, dim=1) # probabilities\n",
        "\n",
        "  break"
      ],
      "metadata": {
        "id": "dwVvDPqO9fL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display texts\n",
        "index_to_display = 5\n",
        "texts[index_to_display]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKLipnj89p-B",
        "outputId": "7065c88b-7e81-4afd-ec8e-55c854c0f877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('I deserve to have my dog walked by my husband every day.',\n",
              " tensor(1, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display labels\n",
        "label[index_to_display]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfP9XBX89tk3",
        "outputId": "996f3afc-d1e4-489c-b363-b4e70fb2d0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display probabilities\n",
        "p[index_to_display]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI8uJjzW9umA",
        "outputId": "4e1f1f2e-b216-4694-cb96-066ed6cdcb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6562, 0.3438], device='cuda:0', grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}